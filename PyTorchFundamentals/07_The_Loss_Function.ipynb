{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90e0bc93-8012-494c-bf9f-9600403d3a60",
   "metadata": {},
   "source": [
    "## The Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d39b8e-ebeb-4327-9bf2-700aa04ddea4",
   "metadata": {},
   "source": [
    "In the last two exercises, we predicted the rent of some apartments by feeding them through neural networks. The networks were untrained, so the predictions weren’t very good.\n",
    "\n",
    "Let’s start improving those predictions!\n",
    "\n",
    "To make better predictions, we first need to know how bad our current predictions are and how to track improvement as we train our model.\n",
    "\n",
    "This is the role of the **loss function**. The loss function is a mathematical formula used to measure the error (also known as loss values) between the model predictions and the actual target values (sometimes called labels) the model is trying to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18108c6c-a92f-4999-b931-b60f71627b7e",
   "metadata": {},
   "source": [
    "### Difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda05f26-f18a-4827-9736-9e0d88f10c3d",
   "metadata": {},
   "source": [
    "Suppose we run a neural network on an apartment with $1000/mo rent, but the network predicts $500/mo. The simplest way to measure the loss in this case is to calculate the difference\n",
    "\n",
    "$$\n",
    "500−1000=−500\n",
    "$$\n",
    "\n",
    "The difference indicates that the prediction was `500` dollars below the actual rent.\n",
    "\n",
    "For just one data point, the difference seems reasonable. But imagine we have a second apartment with rent $1500, but the model **overestimates** the rent as $2000. The difference in this case is\n",
    "\n",
    "$$\n",
    "2000−1500=500\n",
    "$$\n",
    "\n",
    "With one loss of `500` and another of `-500`, the average loss for the model is actually `0`! But that doesn’t make sense, since this network isn’t perfectly accurate.\n",
    "\n",
    "The problem is that the negative loss cancelled out the positive loss. To fix this, we need to force the difference to always be positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f232d1-1e44-4eec-84ab-92cf2284125d",
   "metadata": {},
   "source": [
    "### Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea7e28c-c972-49bf-b633-b507ffdc9c36",
   "metadata": {},
   "source": [
    "One of the most common loss functions is Mean Squared Error (MSE). MSE makes differences positive by squaring them. To calculate MSE on our two example apartments, we would\n",
    "\n",
    "- calculate the diffferences: `500`, `-500`\n",
    "- square both: `500^2`, `(-500)^2`\n",
    "- take the average:\n",
    "$$\n",
    "\\frac{(500 - 1000)^2 + (1500 - 1000)^2}{2} = 250{,}000\n",
    "$$\n",
    "A loss of `250,000` seems very high, but remember that we’ve squared all the individual differences. To help interpret MSE, we’ll sometimes take the square root of the MSE:\n",
    "\n",
    "$$\n",
    "\\sqrt{250000} = 500\n",
    "$$\n",
    "\n",
    "An average loss of `500` makes a lot of sense in this case!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66408285-2794-405b-b092-d9f576273d09",
   "metadata": {},
   "source": [
    "### MSE in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee352d04-c3fa-49af-a076-531c327481f0",
   "metadata": {},
   "source": [
    "PyTorch has already implemented most of the common loss functions. To use PyTorch’s implementation of MSE, we’d run\n",
    "\n",
    "```pyhton\n",
    "loss = nn.MSELoss()\n",
    "```\n",
    "\n",
    "Now that we’ve instantiated `loss`, we can compute the mean squared error by passing two inputs:\n",
    "- the predicted values\n",
    "- the actual target values\n",
    "\n",
    "Just as we use `X` to stand for input features in a neural network, it is common in machine learning to use the variable `y` to stand for the target values. In this case, our target isn’t two-dimensional, so we use lowercase `y`.\n",
    "\n",
    "Let’s calculate MSE for our two example apartments:\n",
    "\n",
    "```python\n",
    "predictions = torch.tensor([500,2000],dtype=torch.float)\n",
    "y = torch.tensor([1000,1500],dtype=torch.float)\n",
    "print(loss(predictions,y))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63b4874-33d4-4127-9de9-f6a8c7c6a358",
   "metadata": {},
   "source": [
    "### Choosing a Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e92c86-58f6-4f40-a0df-e2d8827c4738",
   "metadata": {},
   "source": [
    "The loss function plays a key role in training, so it is important to select the right one. Sometimes it is worth experimenting with a few different loss functions, to see how each behaves.\n",
    "\n",
    "For example, the squaring process in MSE emphasizes the largest differences between predicted and target values. Sometimes, this is helpful, but in other cases it can lead to overfitting. In those cases, instead of *squaring* differences we might choose to take the *absolute value* to produce positive values (this is called the **Mean Absolute Error**)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
