{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7db57078-dce8-4094-a558-8d1dc0ed3232",
   "metadata": {},
   "source": [
    "## The Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997aec41-5707-4f7c-a9b5-a76cbea38283",
   "metadata": {},
   "source": [
    "With a loss function, we can tell how well (or poorly!) our neural network is performing. To improve on our model’s performance, we need to adjust the weights and biases. This is what the **optimizer algorithm** does!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84bf27a-2dfd-4ffb-a745-513350c2deb0",
   "metadata": {},
   "source": [
    "### Gradient Descent Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a08e7c-1e24-4741-99a4-0d605922f24f",
   "metadata": {},
   "source": [
    "There are many different optimization algorithms. One of the most common is called **gradient descent**.\n",
    "\n",
    "Imagine we’re on top of a mountain, and our loss function tells us how high up we are. Our goal is to get down the mountain, making the loss function as small as possible. Unfortunately, it’s a dark night, so even with perfect sight we couldn’t see very far.\n",
    "\n",
    "Suppose (using sight or some kind of radar) we can determine how the mountain slopes around us for about a meter in any direction. With only that information, we might pick where the mountain slopes down the most and move in that direction.\n",
    "\n",
    "We don’t want to move too far at once, because the mountain slope might change as we move. So we’ll only move a short distance in our chosen direction before pausing and re-evaluating which direction goes downhill the most.\n",
    "\n",
    "This strategy is essentially how gradient descent works! It uses calculus to determine the gradients of the loss function. These **gradients** are the direction signs that indicate which way to adjust the weights and biases in order to decrease the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121c5792-d05d-44d7-b639-02aea7c7bab3",
   "metadata": {},
   "source": [
    "### Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9dba62-8ce7-438d-b727-06c70c5c8c9f",
   "metadata": {},
   "source": [
    "How far to move at each step is called the **learning rate**. Choosing a learning rate involves some tradeoffs:\n",
    "\n",
    "- a learning rate too high may cause the model to move too quickly and miss the lowest point\n",
    "- a learning rate too small may cause the model to learn slowly or get stuck\n",
    "\n",
    "The learning rate is a classic example of what we call **hyperparameters** – values tuned and tweaked by ML engineers during training to improve performance of the model. The process of adjusting hyperparameters in search of the best model performance is called **hyperparameter** tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d99176d-ea25-4db4-a6d5-43dbd1fb5f41",
   "metadata": {},
   "source": [
    "### Using Optimizers in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da30599-27b7-4716-b5ae-0ec2b2fdb996",
   "metadata": {},
   "source": [
    "A popular optimizer in PyTorch, called **Adam**, uses gradient descent with a few extra bells and whistles (like adjusting the learning rate dynamically during training). To use Adam, we’ll use the syntax\n",
    "\n",
    "```python\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "```\n",
    "\n",
    "where\n",
    "- `model.parameters()` tells Adam what our current weights and biases are\n",
    "- `lr=0.01` tells Adam to set the learning rate to `0.01`\n",
    "\n",
    "To apply Adam to a neural network, we need to perform the:\n",
    "1. **backwards pass**: calculate the gradients of the loss function (these determine the “downward” direction)\n",
    "2. **step**: use the gradients to update the weights and biases.\n",
    "\n",
    "The syntax is\n",
    "```python\n",
    "# compute the loss\n",
    "MSE = loss(predictions, y)\n",
    "# backward pass to determine \"downward\" direction\n",
    "MSE.backward()\n",
    "# apply the optimizer to update weights and biases\n",
    "optimizer.step()\n",
    "```\n",
    "\n",
    "Note that `backward` is applied to the computed loss, not the loss function. This is why the output of the `loss` function includes the parameter `grad_fn=<MseLossBackward0>`. This parameter is the function used to perform the backwards pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9d926e-6b1d-40a4-baac-dc60a7c8826c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b19b7ea-298e-4c50-8aa0-951259600cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
